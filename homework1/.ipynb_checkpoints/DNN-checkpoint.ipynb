{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pytorch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare\n",
       "0         0       3    1  22.0      1      0   7.2500\n",
       "1         1       1    0  38.0      1      0  71.2833\n",
       "2         1       3    0  26.0      0      0   7.9250\n",
       "3         1       1    0  35.0      1      0  53.1000\n",
       "4         0       3    1  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex   Age  SibSp  Parch     Fare\n",
      "0       3    1  22.0      1      0   7.2500\n",
      "1       1    0  38.0      1      0  71.2833\n",
      "2       3    0  26.0      0      0   7.9250\n",
      "3       1    0  35.0      1      0  53.1000\n",
      "4       3    1  35.0      0      0   8.0500\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X=df.loc[::,'Pclass': 'Fare']\n",
    "y=df.loc[::,'Survived']\n",
    "print((X.head()))\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.10,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder()\n",
    "dat_y_train=onehotencoder.fit_transform(y_train.values.reshape(len(y_train),1)).toarray()\n",
    "dat_y_test=onehotencoder.fit_transform(y_test.values.reshape(len(y_test),1)).toarray()\n",
    "#pd.DataFrame(data_str_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 6, 1) (801, 2, 1)\n",
      "(90, 6, 1) (90, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.values.reshape(len(X_train),-1,1)\n",
    "y_train=dat_y_train.reshape(len(dat_y_train),-1,1)\n",
    "X_test=X_test.values.reshape(len(X_test),-1,1)\n",
    "y_test=dat_y_test.reshape(len(dat_y_test),-1,1)\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = list(zip(X_train, y_train))\n",
    "testing_data = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.   ],\n",
       "        [ 0.   ],\n",
       "        [ 9.   ],\n",
       "        [ 4.   ],\n",
       "        [ 2.   ],\n",
       "        [31.275]]), array([[1.],\n",
       "        [0.]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "def sigmoid_derivate(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "def cross_entropy(output, ground_truth):\n",
    "    return np.sum( np.nan_to_num( -ground_truth*np.log(output) - (1-ground_truth)*np.log(1-output) ) )\n",
    "def cross_entropy_derivative(output, ground_truth):\n",
    "    return output - ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for w, b in zip(self.weights, self.biases):\n",
    "            x = np.dot(w, x) + b #w has been transposed so dot as\n",
    "            z.append(x)\n",
    "            x = sigmoid(x)\n",
    "            activation_z.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self,neurons):\n",
    "        self.layers=len(neurons)\n",
    "        self.neurons=neurons\n",
    "        self.weights = [ np.zeros((i, j)) for i, j in zip(neurons[1:], neurons[:-1]) ]# inverse\n",
    "        self.biases = [ np.zeros((i, 1)) for i in neurons[1:] ]\n",
    "        # info \n",
    "        self.training_loss = []\n",
    "        self.training_error_rate = []\n",
    "        self.testing_error_rate = []\n",
    "    def SDG(self,train_data,test_data,epochs,batch_size,lr):\n",
    "        num = len(train_data)\n",
    "        self.training_loss = []\n",
    "        self.training_error_rate = []\n",
    "        self.testing_error_rate = []\n",
    "        evaluation_cost, evaluation_accuracy = [], []\n",
    "        training_cost, training_accuracy = [], []\n",
    "        for i in range(epochs):\n",
    "            random.shuffle(train_data)\n",
    "            mini_batch = [train_data[j:j+batch_size] for j in range(0,num,batch_size) ]\n",
    "            for data in mini_batch:\n",
    "                self.update_mini_batch(data,lr)\n",
    "                if (i % int(i/20) == 0):\n",
    "                    # record info\n",
    "                    self.training_loss.append(self.calc_loss(train_data))\n",
    "                    self.training_error_rate.append(self.count_error(train_data) / len(train_data))\n",
    "                    self.testing_error_rate.append(self.count_error(test_data) / len(test_data))\n",
    "                    print(\"--------------\")\n",
    "                    print(\"【Epoch %s】\" % i)\n",
    "                    print(\"loss rate for trainingdata = %d\")\n",
    "    def update_mini_batch(self, single_data, lr):\n",
    "        sum_gradient_w = [ np.zeros(w.shape) for w in self.weights ] #creat same size as weight think as 暫存器\n",
    "        sum_gradient_b = [ np.zeros(b.shape) for b in self.biases ]\n",
    "        \n",
    "        # cumulate gradient of each single data\n",
    "        for x, y in single_data:\n",
    "            gradient_w, gradient_b = self.backward(x, y)\n",
    "            sum_gradient_w = [  sw + w for sw, w in zip(sum_gradient_w, gradient_w)]\n",
    "            sum_gradient_b = [ sb + b for sb, b in zip(sum_gradient_b, gradient_b)]\n",
    "        \n",
    "        # update weights & biases with (mean of sum of gradient * learning rate)\n",
    "        self.weights = [ w - lr/len(single_data) * sw for w, sw in zip(self.weights, sum_gradient_w) ]\n",
    "        self.biases = [ b - lr/len(single_data) * sb for b, sb in zip(self.biases, sum_gradient_b) ]\n",
    "    def forward(self, x):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            x = np.dot(w, x) + b\n",
    "            x = sigmoid(x)\n",
    "        return x\n",
    "    def backward(self,prediction,ground_truth):\n",
    "        gradient_w=[np.zeros(w.shape) for w in self.weights ]\n",
    "        gradient_b=[np.zeros(b.shape) for b in self.biases ]\n",
    "        loss=cross_entropy_derivative(prediciton,ground_truth) # matrix base\n",
    "        backpropagation_1st_layer=cross_entropy(prediction,ground_truth)\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN=[6,3,3,2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
